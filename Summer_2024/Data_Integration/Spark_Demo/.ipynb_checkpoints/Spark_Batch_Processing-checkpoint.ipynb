{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f09c491e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T23:36:48.954646Z",
     "start_time": "2024-08-29T23:36:48.790035Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta, MO, SU\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as t\n",
    "from pyspark.sql.window import Window as w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dfc71aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:43:28.693980Z",
     "start_time": "2024-08-23T23:43:26.451372Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/30 02:38:17 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .appName(\"SparkDemo\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659d957d",
   "metadata": {},
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb9dab44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:43:30.490575Z",
     "start_time": "2024-08-23T23:43:29.393619Z"
    }
   },
   "outputs": [],
   "source": [
    "video_categories_df = spark.read.format(\"json\") \\\n",
    "    .option(\"multiline\",\"true\") \\\n",
    "    .load(f\"./data/GB_category_id.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54af7094",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:43:30.501831Z",
     "start_time": "2024-08-23T23:43:30.490995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- etag: string (nullable = true)\n",
      " |-- items: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- etag: string (nullable = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- kind: string (nullable = true)\n",
      " |    |    |-- snippet: struct (nullable = true)\n",
      " |    |    |    |-- assignable: boolean (nullable = true)\n",
      " |    |    |    |-- channelId: string (nullable = true)\n",
      " |    |    |    |-- title: string (nullable = true)\n",
      " |-- kind: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "video_categories_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed357523",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:43:41.892813Z",
     "start_time": "2024-08-23T23:43:41.112739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Film &amp; Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Autos &amp; Vehicles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>Pets &amp; Animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id             title\n",
       "0   1  Film & Animation\n",
       "1   2  Autos & Vehicles\n",
       "2  10             Music\n",
       "3  15    Pets & Animals\n",
       "4  17            Sports"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_categories_df = (\n",
    "    video_categories_df\n",
    "        .withColumn(\"categories\", F.explode(F.arrays_zip(\"items.id\", \"items.snippet.title\")))\n",
    "        .select(\n",
    "            col(\"categories\")[\"id\"].alias(\"id\"),\n",
    "            col(\"categories\")[\"title\"].alias(\"title\"),\n",
    "        )\n",
    ")\n",
    "video_categories_df.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcdcf0eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:43:43.350623Z",
     "start_time": "2024-08-23T23:43:43.148209Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jw1Y-zhQURU</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>John Lewis Christmas Ad 2017 - #MozTheMonster</td>\n",
       "      <td>John Lewis</td>\n",
       "      <td>26</td>\n",
       "      <td>2017-11-10T07:38:29.000Z</td>\n",
       "      <td>\"christmas\"|\"john lewis christmas\"|\"john lewis...</td>\n",
       "      <td>7224515</td>\n",
       "      <td>55681</td>\n",
       "      <td>10247</td>\n",
       "      <td>9479</td>\n",
       "      <td>https://i.ytimg.com/vi/Jw1Y-zhQURU/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Click here to continue the story and make your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3s1rvMFUweQ</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Taylor Swift: …Ready for It? (Live) - SNL</td>\n",
       "      <td>Saturday Night Live</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-12T06:24:44.000Z</td>\n",
       "      <td>\"SNL\"|\"Saturday Night Live\"|\"SNL Season 43\"|\"E...</td>\n",
       "      <td>1053632</td>\n",
       "      <td>25561</td>\n",
       "      <td>2294</td>\n",
       "      <td>2757</td>\n",
       "      <td>https://i.ytimg.com/vi/3s1rvMFUweQ/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Musical guest Taylor Swift performs …Ready for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n1WpP7iowLc</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Eminem - Walk On Water (Audio) ft. Beyoncé</td>\n",
       "      <td>EminemVEVO</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-11-10T17:00:03.000Z</td>\n",
       "      <td>\"Eminem\"|\"Walk\"|\"On\"|\"Water\"|\"Aftermath/Shady/...</td>\n",
       "      <td>17158579</td>\n",
       "      <td>787420</td>\n",
       "      <td>43420</td>\n",
       "      <td>125882</td>\n",
       "      <td>https://i.ytimg.com/vi/n1WpP7iowLc/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Eminem's new track Walk on Water ft. Beyoncé i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PUTEiSjKwJU</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Goals from Salford City vs Class of 92 and Fri...</td>\n",
       "      <td>Salford City Football Club</td>\n",
       "      <td>17</td>\n",
       "      <td>2017-11-13T02:30:38.000Z</td>\n",
       "      <td>\"Salford City FC\"|\"Salford City\"|\"Salford\"|\"Cl...</td>\n",
       "      <td>27833</td>\n",
       "      <td>193</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>https://i.ytimg.com/vi/PUTEiSjKwJU/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Salford drew 4-4 against the Class of 92 and F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rHwDegptbI4</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Dashcam captures truck's near miss with child ...</td>\n",
       "      <td>Cute Girl Videos</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-11-13T01:45:13.000Z</td>\n",
       "      <td>[none]</td>\n",
       "      <td>9815</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>https://i.ytimg.com/vi/rHwDegptbI4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Dashcam captures truck's near miss with child ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  Jw1Y-zhQURU      17.14.11   \n",
       "1  3s1rvMFUweQ      17.14.11   \n",
       "2  n1WpP7iowLc      17.14.11   \n",
       "3  PUTEiSjKwJU      17.14.11   \n",
       "4  rHwDegptbI4      17.14.11   \n",
       "\n",
       "                                               title  \\\n",
       "0      John Lewis Christmas Ad 2017 - #MozTheMonster   \n",
       "1          Taylor Swift: …Ready for It? (Live) - SNL   \n",
       "2         Eminem - Walk On Water (Audio) ft. Beyoncé   \n",
       "3  Goals from Salford City vs Class of 92 and Fri...   \n",
       "4  Dashcam captures truck's near miss with child ...   \n",
       "\n",
       "                channel_title category_id              publish_time  \\\n",
       "0                  John Lewis          26  2017-11-10T07:38:29.000Z   \n",
       "1         Saturday Night Live          24  2017-11-12T06:24:44.000Z   \n",
       "2                  EminemVEVO          10  2017-11-10T17:00:03.000Z   \n",
       "3  Salford City Football Club          17  2017-11-13T02:30:38.000Z   \n",
       "4            Cute Girl Videos          25  2017-11-13T01:45:13.000Z   \n",
       "\n",
       "                                                tags     views   likes  \\\n",
       "0  \"christmas\"|\"john lewis christmas\"|\"john lewis...   7224515   55681   \n",
       "1  \"SNL\"|\"Saturday Night Live\"|\"SNL Season 43\"|\"E...   1053632   25561   \n",
       "2  \"Eminem\"|\"Walk\"|\"On\"|\"Water\"|\"Aftermath/Shady/...  17158579  787420   \n",
       "3  \"Salford City FC\"|\"Salford City\"|\"Salford\"|\"Cl...     27833     193   \n",
       "4                                             [none]      9815      30   \n",
       "\n",
       "  dislikes comment_count                                  thumbnail_link  \\\n",
       "0    10247          9479  https://i.ytimg.com/vi/Jw1Y-zhQURU/default.jpg   \n",
       "1     2294          2757  https://i.ytimg.com/vi/3s1rvMFUweQ/default.jpg   \n",
       "2    43420        125882  https://i.ytimg.com/vi/n1WpP7iowLc/default.jpg   \n",
       "3       12            37  https://i.ytimg.com/vi/PUTEiSjKwJU/default.jpg   \n",
       "4        2            30  https://i.ytimg.com/vi/rHwDegptbI4/default.jpg   \n",
       "\n",
       "  comments_disabled ratings_disabled video_error_or_removed  \\\n",
       "0             False            False                  False   \n",
       "1             False            False                  False   \n",
       "2             False            False                  False   \n",
       "3             False            False                  False   \n",
       "4             False            False                  False   \n",
       "\n",
       "                                         description  \n",
       "0  Click here to continue the story and make your...  \n",
       "1  Musical guest Taylor Swift performs …Ready for...  \n",
       "2  Eminem's new track Walk on Water ft. Beyoncé i...  \n",
       "3  Salford drew 4-4 against the Class of 92 and F...  \n",
       "4  Dashcam captures truck's near miss with child ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"multiline\", True) \\\n",
    "    .option(\"sep\", \",\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .load(\"./data/GBvideos.csv\")\n",
    "\n",
    "videos_df.limit(10).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043a6bb1",
   "metadata": {},
   "source": [
    "### Check nulls in each column in dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4ab1c1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:43:45.324635Z",
     "start_time": "2024-08-23T23:43:45.060922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  title\n",
       "0   0      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_categories_df.select([F.count(F.when(F.isnan(c), c)).alias(c) for c in video_categories_df.columns]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbbfc817",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:43:46.708492Z",
     "start_time": "2024-08-23T23:43:45.325425Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_id  trending_date  title  channel_title  category_id  publish_time  \\\n",
       "0         0              0      0              0            0             0   \n",
       "\n",
       "   tags  views  likes  dislikes  comment_count  thumbnail_link  \\\n",
       "0     0      0      0         0              0               0   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  description  \n",
       "0                  0                 0                       0            0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_df.select([F.count(F.when(F.isnan(c), c)).alias(c) for c in videos_df.columns]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "587fba62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:43:47.246691Z",
     "start_time": "2024-08-23T23:43:46.707974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(trending_date='18.08.05'),\n",
       " Row(trending_date='17.20.11'),\n",
       " Row(trending_date='17.09.12'),\n",
       " Row(trending_date='18.14.02'),\n",
       " Row(trending_date='18.20.03'),\n",
       " Row(trending_date='18.04.05'),\n",
       " Row(trending_date='18.21.02'),\n",
       " Row(trending_date='18.30.04'),\n",
       " Row(trending_date='18.06.05'),\n",
       " Row(trending_date='18.11.02')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_df.select(['trending_date']).distinct().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87ba25c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:43:47.246915Z",
     "start_time": "2024-08-23T23:43:47.229037Z"
    }
   },
   "outputs": [],
   "source": [
    "def df_print(df, n_rows=5):\n",
    "    return df.limit(n_rows).toPandas().head(n_rows)\n",
    "\n",
    "\n",
    "def convert_df_to_column_array(old_df, from_col, to_col):\n",
    "    new_df = (\n",
    "        old_df\n",
    "            .agg(F.collect_list(col(from_col)).alias(to_col))\n",
    "            .select([to_col])\n",
    "    )\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c45254",
   "metadata": {},
   "source": [
    "## Query 1\n",
    "\n",
    "**Description:** Find Top 10 videos that were amongst the trending videos for the highest\n",
    "number of days (it doesn't need to be a consecutive period of time).\n",
    "You should also include information about different metrics for each day\n",
    "the video was trending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dec46d69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:43:49.330738Z",
     "start_time": "2024-08-23T23:43:48.902782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>num_trending_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2z3EUY1aXdY</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NooW_RbfdWI</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Il-an3K9pjg</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BhIEIO0vaBE</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u_C4onVrr8U</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8h--kFui1JA</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tGRzz0oqgUE</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5GHXEGz3PJg</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tsp7IOr7Q9A</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dzxFdtWmjto</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id  num_trending_days\n",
       "0  2z3EUY1aXdY                 38\n",
       "1  NooW_RbfdWI                 38\n",
       "2  Il-an3K9pjg                 38\n",
       "3  BhIEIO0vaBE                 38\n",
       "4  u_C4onVrr8U                 38\n",
       "5  8h--kFui1JA                 37\n",
       "6  tGRzz0oqgUE                 37\n",
       "7  5GHXEGz3PJg                 37\n",
       "8  tsp7IOr7Q9A                 37\n",
       "9  dzxFdtWmjto                 37"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create initial dataframe for the query\n",
    "df = videos_df.select(\n",
    "    col('video_id'),\n",
    "    col(\"title\"),\n",
    "    col(\"description\"),\n",
    "    F.struct(\n",
    "        F.to_date(F.from_unixtime(F.unix_timestamp(col(\"trending_date\"), \"yy.dd.MM\"))).alias(\"date\"), \n",
    "        col(\"likes\").cast(t.LongType()).alias(\"likes\"), \n",
    "        col(\"dislikes\").cast(t.LongType()).alias(\"dislikes\"),\n",
    "        col(\"views\").cast(t.LongType()).alias(\"views\")\n",
    "    ).alias('trending_day')\n",
    ")\n",
    "\n",
    "# Get top 10 most trending video ids\n",
    "most_trending_df = df.groupBy(df.video_id)\\\n",
    "                        .agg(F.count('video_id').alias('num_trending_days'))\\\n",
    "                        .sort(col('num_trending_days').desc()).limit(10)\n",
    "df_print(most_trending_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5357f5ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:43:50.013076Z",
     "start_time": "2024-08-23T23:43:49.325170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>num_trending_days</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>trending_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BhIEIO0vaBE</td>\n",
       "      <td>38</td>\n",
       "      <td>To Our Daughter</td>\n",
       "      <td>Directed by Tyler Ross @wttyler\\nMusic by Jaco...</td>\n",
       "      <td>(2018-02-05, 0, 0, 20921796)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NooW_RbfdWI</td>\n",
       "      <td>38</td>\n",
       "      <td>Jurassic World: Fallen Kingdom - Official Trai...</td>\n",
       "      <td>Jurassic World: Fallen Kingdom \\nIn Theaters J...</td>\n",
       "      <td>(2018-02-05, 61833, 1416, 1999326)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2z3EUY1aXdY</td>\n",
       "      <td>38</td>\n",
       "      <td>Justin Timberlake’s FULL Pepsi Super Bowl LII ...</td>\n",
       "      <td>Justin Timberlake breaks it down during the Pe...</td>\n",
       "      <td>(2018-02-05, 50251, 15239, 2027569)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BhIEIO0vaBE</td>\n",
       "      <td>38</td>\n",
       "      <td>To Our Daughter</td>\n",
       "      <td>Directed by Tyler Ross @wttyler\\nMusic by Jaco...</td>\n",
       "      <td>(2018-02-06, 0, 0, 35832484)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2z3EUY1aXdY</td>\n",
       "      <td>38</td>\n",
       "      <td>Justin Timberlake’s FULL Pepsi Super Bowl LII ...</td>\n",
       "      <td>Justin Timberlake breaks it down during the Pe...</td>\n",
       "      <td>(2018-02-06, 123302, 39422, 8313413)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id  num_trending_days  \\\n",
       "0  BhIEIO0vaBE                 38   \n",
       "1  NooW_RbfdWI                 38   \n",
       "2  2z3EUY1aXdY                 38   \n",
       "3  BhIEIO0vaBE                 38   \n",
       "4  2z3EUY1aXdY                 38   \n",
       "\n",
       "                                               title  \\\n",
       "0                                    To Our Daughter   \n",
       "1  Jurassic World: Fallen Kingdom - Official Trai...   \n",
       "2  Justin Timberlake’s FULL Pepsi Super Bowl LII ...   \n",
       "3                                    To Our Daughter   \n",
       "4  Justin Timberlake’s FULL Pepsi Super Bowl LII ...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Directed by Tyler Ross @wttyler\\nMusic by Jaco...   \n",
       "1  Jurassic World: Fallen Kingdom \\nIn Theaters J...   \n",
       "2  Justin Timberlake breaks it down during the Pe...   \n",
       "3  Directed by Tyler Ross @wttyler\\nMusic by Jaco...   \n",
       "4  Justin Timberlake breaks it down during the Pe...   \n",
       "\n",
       "                           trending_day  \n",
       "0          (2018-02-05, 0, 0, 20921796)  \n",
       "1    (2018-02-05, 61833, 1416, 1999326)  \n",
       "2   (2018-02-05, 50251, 15239, 2027569)  \n",
       "3          (2018-02-06, 0, 0, 35832484)  \n",
       "4  (2018-02-06, 123302, 39422, 8313413)  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get title, description and trending_day for each video from top 10\n",
    "detailed_most_trending_df = most_trending_df.alias('df1').join(\n",
    "    df.alias('df2'), col('df1.video_id') == col('df2.video_id'), 'inner')\\\n",
    "        .select(\n",
    "            col('df1.video_id').alias('video_id'),\n",
    "            col('num_trending_days'),\n",
    "            col('title'),\n",
    "            col('description'),\n",
    "            col('trending_day')\n",
    "        )\n",
    "df_print(detailed_most_trending_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b8c9caa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:43:51.396654Z",
     "start_time": "2024-08-23T23:43:50.561925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>latest_likes</th>\n",
       "      <th>latest_dislikes</th>\n",
       "      <th>latest_views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2z3EUY1aXdY</td>\n",
       "      <td>Justin Timberlake’s FULL Pepsi Super Bowl LII ...</td>\n",
       "      <td>Justin Timberlake breaks it down during the Pe...</td>\n",
       "      <td>169320</td>\n",
       "      <td>54005</td>\n",
       "      <td>14251760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5GHXEGz3PJg</td>\n",
       "      <td>Florence + The Machine - Hunger</td>\n",
       "      <td>HungerDirected by AG RojasProduced by Park Pic...</td>\n",
       "      <td>171071</td>\n",
       "      <td>3972</td>\n",
       "      <td>12293782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8h--kFui1JA</td>\n",
       "      <td>Sam Smith - Pray (Official Video) ft. Logic</td>\n",
       "      <td>Stream, Download and Listen to Pray feat. Logi...</td>\n",
       "      <td>370027</td>\n",
       "      <td>9680</td>\n",
       "      <td>22999573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BhIEIO0vaBE</td>\n",
       "      <td>To Our Daughter</td>\n",
       "      <td>Directed by Tyler Ross @wttyler\\nMusic by Jaco...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62338362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Il-an3K9pjg</td>\n",
       "      <td>Anne-Marie - 2002 [Official Video]</td>\n",
       "      <td>Get 2002 by Anne-Marie HERE ▶ http://ad.gt/200...</td>\n",
       "      <td>394830</td>\n",
       "      <td>8892</td>\n",
       "      <td>29641412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NooW_RbfdWI</td>\n",
       "      <td>Jurassic World: Fallen Kingdom - Official Trai...</td>\n",
       "      <td>Jurassic World: Fallen Kingdom \\nIn Theaters J...</td>\n",
       "      <td>275268</td>\n",
       "      <td>7806</td>\n",
       "      <td>24293173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dzxFdtWmjto</td>\n",
       "      <td>VENOM - Official Teaser Trailer (HD)</td>\n",
       "      <td>Watch the #Venom teaser trailer now. 10.5.18.\\...</td>\n",
       "      <td>219113</td>\n",
       "      <td>25700</td>\n",
       "      <td>16416756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tGRzz0oqgUE</td>\n",
       "      <td>Janelle Monáe – Make Me Feel [Official Music V...</td>\n",
       "      <td>“Make Me Feel” and “Django Jane” available now...</td>\n",
       "      <td>150947</td>\n",
       "      <td>9745</td>\n",
       "      <td>8585663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tsp7IOr7Q9A</td>\n",
       "      <td>BHAD BHABIE feat. Lil Yachty - Gucci Flip Flop...</td>\n",
       "      <td>BHAD BHABIE Gucci Flip Flops ft. Lil Yachty ⛵️...</td>\n",
       "      <td>873431</td>\n",
       "      <td>119401</td>\n",
       "      <td>50122125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>u_C4onVrr8U</td>\n",
       "      <td>Miguel - Come Through and Chill (Official Vide...</td>\n",
       "      <td>“Come Through and Chill” ft. J. Cole out now! ...</td>\n",
       "      <td>152765</td>\n",
       "      <td>3266</td>\n",
       "      <td>9657370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                              title  \\\n",
       "0  2z3EUY1aXdY  Justin Timberlake’s FULL Pepsi Super Bowl LII ...   \n",
       "1  5GHXEGz3PJg                    Florence + The Machine - Hunger   \n",
       "2  8h--kFui1JA        Sam Smith - Pray (Official Video) ft. Logic   \n",
       "3  BhIEIO0vaBE                                    To Our Daughter   \n",
       "4  Il-an3K9pjg                 Anne-Marie - 2002 [Official Video]   \n",
       "5  NooW_RbfdWI  Jurassic World: Fallen Kingdom - Official Trai...   \n",
       "6  dzxFdtWmjto               VENOM - Official Teaser Trailer (HD)   \n",
       "7  tGRzz0oqgUE  Janelle Monáe – Make Me Feel [Official Music V...   \n",
       "8  tsp7IOr7Q9A  BHAD BHABIE feat. Lil Yachty - Gucci Flip Flop...   \n",
       "9  u_C4onVrr8U  Miguel - Come Through and Chill (Official Vide...   \n",
       "\n",
       "                                         description  latest_likes  \\\n",
       "0  Justin Timberlake breaks it down during the Pe...        169320   \n",
       "1  HungerDirected by AG RojasProduced by Park Pic...        171071   \n",
       "2  Stream, Download and Listen to Pray feat. Logi...        370027   \n",
       "3  Directed by Tyler Ross @wttyler\\nMusic by Jaco...             0   \n",
       "4  Get 2002 by Anne-Marie HERE ▶ http://ad.gt/200...        394830   \n",
       "5  Jurassic World: Fallen Kingdom \\nIn Theaters J...        275268   \n",
       "6  Watch the #Venom teaser trailer now. 10.5.18.\\...        219113   \n",
       "7  “Make Me Feel” and “Django Jane” available now...        150947   \n",
       "8  BHAD BHABIE Gucci Flip Flops ft. Lil Yachty ⛵️...        873431   \n",
       "9  “Come Through and Chill” ft. J. Cole out now! ...        152765   \n",
       "\n",
       "   latest_dislikes  latest_views  \n",
       "0            54005      14251760  \n",
       "1             3972      12293782  \n",
       "2             9680      22999573  \n",
       "3                0      62338362  \n",
       "4             8892      29641412  \n",
       "5             7806      24293173  \n",
       "6            25700      16416756  \n",
       "7             9745       8585663  \n",
       "8           119401      50122125  \n",
       "9             3266       9657370  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the latest day video statistics\n",
    "window = w.partitionBy(\"video_id\").orderBy(col(\"trending_day.date\").desc())\n",
    "latest_day_info_df = detailed_most_trending_df.withColumn(\"rank\", F.row_number().over(window)) \\\n",
    "                        .where(col(\"rank\") == 1) \\\n",
    "                        .select(\n",
    "                            col(\"video_id\"), \n",
    "                            col(\"title\"), \n",
    "                            col(\"description\"), \n",
    "                            col(\"trending_day.likes\").alias(\"latest_likes\"), \n",
    "                            col(\"trending_day.dislikes\").alias(\"latest_dislikes\"),\n",
    "                            col(\"trending_day.views\").alias(\"latest_views\")\n",
    "                        )\n",
    "df_print(latest_day_info_df, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee2a7381",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:43:53.414057Z",
     "start_time": "2024-08-23T23:43:52.483532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2z3EUY1aXdY</td>\n",
       "      <td>[(2018-03-14, 169320, 54005, 14251760), (2018-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5GHXEGz3PJg</td>\n",
       "      <td>[(2018-06-09, 171071, 3972, 12293782), (2018-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8h--kFui1JA</td>\n",
       "      <td>[(2018-06-14, 370027, 9680, 22999573), (2018-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BhIEIO0vaBE</td>\n",
       "      <td>[(2018-03-14, 0, 0, 62338362), (2018-03-13, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Il-an3K9pjg</td>\n",
       "      <td>[(2018-06-14, 394830, 8892, 29641412), (2018-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NooW_RbfdWI</td>\n",
       "      <td>[(2018-03-14, 275268, 7806, 24293173), (2018-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dzxFdtWmjto</td>\n",
       "      <td>[(2018-03-17, 219113, 25700, 16416756), (2018-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tGRzz0oqgUE</td>\n",
       "      <td>[(2018-03-31, 150947, 9745, 8585663), (2018-03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tsp7IOr7Q9A</td>\n",
       "      <td>[(2018-06-07, 873431, 119401, 50122125), (2018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>u_C4onVrr8U</td>\n",
       "      <td>[(2018-06-01, 152765, 3266, 9657370), (2018-05...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                      trending_days\n",
       "0  2z3EUY1aXdY  [(2018-03-14, 169320, 54005, 14251760), (2018-...\n",
       "1  5GHXEGz3PJg  [(2018-06-09, 171071, 3972, 12293782), (2018-0...\n",
       "2  8h--kFui1JA  [(2018-06-14, 370027, 9680, 22999573), (2018-0...\n",
       "3  BhIEIO0vaBE  [(2018-03-14, 0, 0, 62338362), (2018-03-13, 0,...\n",
       "4  Il-an3K9pjg  [(2018-06-14, 394830, 8892, 29641412), (2018-0...\n",
       "5  NooW_RbfdWI  [(2018-03-14, 275268, 7806, 24293173), (2018-0...\n",
       "6  dzxFdtWmjto  [(2018-03-17, 219113, 25700, 16416756), (2018-...\n",
       "7  tGRzz0oqgUE  [(2018-03-31, 150947, 9745, 8585663), (2018-03...\n",
       "8  tsp7IOr7Q9A  [(2018-06-07, 873431, 119401, 50122125), (2018...\n",
       "9  u_C4onVrr8U  [(2018-06-01, 152765, 3266, 9657370), (2018-05..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all trending days for top 10 videos\n",
    "trending_days_df = latest_day_info_df.alias('df1')\\\n",
    "                            .join(df.alias('df2'),\n",
    "                                    col('df1.video_id') == col('df2.video_id'), how='inner')\\\n",
    "                            .select(\n",
    "                                col('df1.video_id').alias('video_id'),\n",
    "                                col('trending_day')\n",
    "                            )\n",
    "trending_days_df = trending_days_df.groupBy(\"video_id\")\\\n",
    "                                    .agg(F.collect_list(col(\"trending_day\")).alias(\"trending_days\"))\n",
    "df_print(trending_days_df, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2f51124",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:43:55.181293Z",
     "start_time": "2024-08-23T23:43:54.265603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>latest_views</th>\n",
       "      <th>latest_likes</th>\n",
       "      <th>latest_dislikes</th>\n",
       "      <th>trending_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2z3EUY1aXdY</td>\n",
       "      <td>Justin Timberlake’s FULL Pepsi Super Bowl LII ...</td>\n",
       "      <td>Justin Timberlake breaks it down during the Pe...</td>\n",
       "      <td>14251760</td>\n",
       "      <td>169320</td>\n",
       "      <td>54005</td>\n",
       "      <td>[(2018-03-14, 169320, 54005, 14251760), (2018-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5GHXEGz3PJg</td>\n",
       "      <td>Florence + The Machine - Hunger</td>\n",
       "      <td>HungerDirected by AG RojasProduced by Park Pic...</td>\n",
       "      <td>12293782</td>\n",
       "      <td>171071</td>\n",
       "      <td>3972</td>\n",
       "      <td>[(2018-06-09, 171071, 3972, 12293782), (2018-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8h--kFui1JA</td>\n",
       "      <td>Sam Smith - Pray (Official Video) ft. Logic</td>\n",
       "      <td>Stream, Download and Listen to Pray feat. Logi...</td>\n",
       "      <td>22999573</td>\n",
       "      <td>370027</td>\n",
       "      <td>9680</td>\n",
       "      <td>[(2018-06-14, 370027, 9680, 22999573), (2018-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BhIEIO0vaBE</td>\n",
       "      <td>To Our Daughter</td>\n",
       "      <td>Directed by Tyler Ross @wttyler\\nMusic by Jaco...</td>\n",
       "      <td>62338362</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(2018-03-14, 0, 0, 62338362), (2018-03-13, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Il-an3K9pjg</td>\n",
       "      <td>Anne-Marie - 2002 [Official Video]</td>\n",
       "      <td>Get 2002 by Anne-Marie HERE ▶ http://ad.gt/200...</td>\n",
       "      <td>29641412</td>\n",
       "      <td>394830</td>\n",
       "      <td>8892</td>\n",
       "      <td>[(2018-06-14, 394830, 8892, 29641412), (2018-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NooW_RbfdWI</td>\n",
       "      <td>Jurassic World: Fallen Kingdom - Official Trai...</td>\n",
       "      <td>Jurassic World: Fallen Kingdom \\nIn Theaters J...</td>\n",
       "      <td>24293173</td>\n",
       "      <td>275268</td>\n",
       "      <td>7806</td>\n",
       "      <td>[(2018-03-14, 275268, 7806, 24293173), (2018-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dzxFdtWmjto</td>\n",
       "      <td>VENOM - Official Teaser Trailer (HD)</td>\n",
       "      <td>Watch the #Venom teaser trailer now. 10.5.18.\\...</td>\n",
       "      <td>16416756</td>\n",
       "      <td>219113</td>\n",
       "      <td>25700</td>\n",
       "      <td>[(2018-03-17, 219113, 25700, 16416756), (2018-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tGRzz0oqgUE</td>\n",
       "      <td>Janelle Monáe – Make Me Feel [Official Music V...</td>\n",
       "      <td>“Make Me Feel” and “Django Jane” available now...</td>\n",
       "      <td>8585663</td>\n",
       "      <td>150947</td>\n",
       "      <td>9745</td>\n",
       "      <td>[(2018-03-31, 150947, 9745, 8585663), (2018-03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tsp7IOr7Q9A</td>\n",
       "      <td>BHAD BHABIE feat. Lil Yachty - Gucci Flip Flop...</td>\n",
       "      <td>BHAD BHABIE Gucci Flip Flops ft. Lil Yachty ⛵️...</td>\n",
       "      <td>50122125</td>\n",
       "      <td>873431</td>\n",
       "      <td>119401</td>\n",
       "      <td>[(2018-06-07, 873431, 119401, 50122125), (2018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>u_C4onVrr8U</td>\n",
       "      <td>Miguel - Come Through and Chill (Official Vide...</td>\n",
       "      <td>“Come Through and Chill” ft. J. Cole out now! ...</td>\n",
       "      <td>9657370</td>\n",
       "      <td>152765</td>\n",
       "      <td>3266</td>\n",
       "      <td>[(2018-06-01, 152765, 3266, 9657370), (2018-05...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                              title  \\\n",
       "0  2z3EUY1aXdY  Justin Timberlake’s FULL Pepsi Super Bowl LII ...   \n",
       "1  5GHXEGz3PJg                    Florence + The Machine - Hunger   \n",
       "2  8h--kFui1JA        Sam Smith - Pray (Official Video) ft. Logic   \n",
       "3  BhIEIO0vaBE                                    To Our Daughter   \n",
       "4  Il-an3K9pjg                 Anne-Marie - 2002 [Official Video]   \n",
       "5  NooW_RbfdWI  Jurassic World: Fallen Kingdom - Official Trai...   \n",
       "6  dzxFdtWmjto               VENOM - Official Teaser Trailer (HD)   \n",
       "7  tGRzz0oqgUE  Janelle Monáe – Make Me Feel [Official Music V...   \n",
       "8  tsp7IOr7Q9A  BHAD BHABIE feat. Lil Yachty - Gucci Flip Flop...   \n",
       "9  u_C4onVrr8U  Miguel - Come Through and Chill (Official Vide...   \n",
       "\n",
       "                                         description  latest_views  \\\n",
       "0  Justin Timberlake breaks it down during the Pe...      14251760   \n",
       "1  HungerDirected by AG RojasProduced by Park Pic...      12293782   \n",
       "2  Stream, Download and Listen to Pray feat. Logi...      22999573   \n",
       "3  Directed by Tyler Ross @wttyler\\nMusic by Jaco...      62338362   \n",
       "4  Get 2002 by Anne-Marie HERE ▶ http://ad.gt/200...      29641412   \n",
       "5  Jurassic World: Fallen Kingdom \\nIn Theaters J...      24293173   \n",
       "6  Watch the #Venom teaser trailer now. 10.5.18.\\...      16416756   \n",
       "7  “Make Me Feel” and “Django Jane” available now...       8585663   \n",
       "8  BHAD BHABIE Gucci Flip Flops ft. Lil Yachty ⛵️...      50122125   \n",
       "9  “Come Through and Chill” ft. J. Cole out now! ...       9657370   \n",
       "\n",
       "   latest_likes  latest_dislikes  \\\n",
       "0        169320            54005   \n",
       "1        171071             3972   \n",
       "2        370027             9680   \n",
       "3             0                0   \n",
       "4        394830             8892   \n",
       "5        275268             7806   \n",
       "6        219113            25700   \n",
       "7        150947             9745   \n",
       "8        873431           119401   \n",
       "9        152765             3266   \n",
       "\n",
       "                                       trending_days  \n",
       "0  [(2018-03-14, 169320, 54005, 14251760), (2018-...  \n",
       "1  [(2018-06-09, 171071, 3972, 12293782), (2018-0...  \n",
       "2  [(2018-06-14, 370027, 9680, 22999573), (2018-0...  \n",
       "3  [(2018-03-14, 0, 0, 62338362), (2018-03-13, 0,...  \n",
       "4  [(2018-06-14, 394830, 8892, 29641412), (2018-0...  \n",
       "5  [(2018-03-14, 275268, 7806, 24293173), (2018-0...  \n",
       "6  [(2018-03-17, 219113, 25700, 16416756), (2018-...  \n",
       "7  [(2018-03-31, 150947, 9745, 8585663), (2018-03...  \n",
       "8  [(2018-06-07, 873431, 119401, 50122125), (2018...  \n",
       "9  [(2018-06-01, 152765, 3266, 9657370), (2018-05...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join and get final results\n",
    "final_df = latest_day_info_df.alias('df1')\\\n",
    "                        .join(trending_days_df.alias('df2'),\n",
    "                              col('df1.video_id') == col('df2.video_id'))\\\n",
    "                        .select(\n",
    "                            col('df1.video_id').alias('video_id'),\n",
    "                            col('title'),\n",
    "                            col('description'),\n",
    "                            col('latest_views'),\n",
    "                            col('latest_likes'),\n",
    "                            col('latest_dislikes'),\n",
    "                            col('trending_days')\n",
    "                        )\n",
    "df_print(final_df, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25933bbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:43:56.065442Z",
     "start_time": "2024-08-23T23:43:55.182095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(2z3EUY1aXdY, Justin Timberlake’s FULL Pepsi S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(5GHXEGz3PJg, Florence + The Machine - Hunger,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(8h--kFui1JA, Sam Smith - Pray (Official Video...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(BhIEIO0vaBE, To Our Daughter, Directed by Tyl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Il-an3K9pjg, Anne-Marie - 2002 [Official Vide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(NooW_RbfdWI, Jurassic World: Fallen Kingdom -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(dzxFdtWmjto, VENOM - Official Teaser Trailer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(tGRzz0oqgUE, Janelle Monáe – Make Me Feel [Of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(tsp7IOr7Q9A, BHAD BHABIE feat. Lil Yachty - G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(u_C4onVrr8U, Miguel - Come Through and Chill ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               video\n",
       "0  (2z3EUY1aXdY, Justin Timberlake’s FULL Pepsi S...\n",
       "1  (5GHXEGz3PJg, Florence + The Machine - Hunger,...\n",
       "2  (8h--kFui1JA, Sam Smith - Pray (Official Video...\n",
       "3  (BhIEIO0vaBE, To Our Daughter, Directed by Tyl...\n",
       "4  (Il-an3K9pjg, Anne-Marie - 2002 [Official Vide...\n",
       "5  (NooW_RbfdWI, Jurassic World: Fallen Kingdom -...\n",
       "6  (dzxFdtWmjto, VENOM - Official Teaser Trailer ...\n",
       "7  (tGRzz0oqgUE, Janelle Monáe – Make Me Feel [Of...\n",
       "8  (tsp7IOr7Q9A, BHAD BHABIE feat. Lil Yachty - G...\n",
       "9  (u_C4onVrr8U, Miguel - Come Through and Chill ..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_videos_df = final_df.select(\n",
    "                            F.struct(\n",
    "                                col(\"video_id\"),\n",
    "                                col('title'),\n",
    "                                col('description'),\n",
    "                                col('latest_views'),\n",
    "                                col('latest_likes'),\n",
    "                                col('latest_dislikes'),\n",
    "                                col('trending_days')\n",
    "                            ).alias(\"video\")\n",
    "                        )\n",
    "df_print(top_videos_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c71539c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:43:56.975022Z",
     "start_time": "2024-08-23T23:43:56.066112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(2z3EUY1aXdY, Justin Timberlake’s FULL Pepsi ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              videos\n",
       "0  [(2z3EUY1aXdY, Justin Timberlake’s FULL Pepsi ..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_videos_df = convert_df_to_column_array(top_videos_df, from_col=\"video\", to_col=\"videos\")\n",
    "df_print(q1_videos_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6d300c",
   "metadata": {},
   "source": [
    "## Query 2\n",
    "\n",
    "**Description:** Find what was the most popular category for each week (7 days slices).\n",
    "Popularity is decided based on the total number of views for videos of\n",
    "this category. Note, to calculate it you can’t just sum up the number of views.\n",
    "If a particular video appeared only once during the given period, it shouldn’t be\n",
    "counted. Only if it appeared more than once you should count the number of new\n",
    "views. For example, if video A appeared on day 1 with 100 views, then on day 4\n",
    "with 250 views and again on day 6 with 400 views, you should count it as 400 - 100 = 300.\n",
    "For our purpose, it will mean that this particular video was watched 300 times\n",
    "in the given time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5df0b29f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:43:56.975274Z",
     "start_time": "2024-08-23T23:43:56.963601Z"
    }
   },
   "outputs": [],
   "source": [
    "week_dates_schema = t.StructType([\n",
    "    t.StructField(\"start_date\", t.DateType()),\n",
    "    t.StructField(\"end_date\", t.DateType())\n",
    "])\n",
    "\n",
    "\n",
    "@F.udf(week_dates_schema)\n",
    "def get_week_dates_udf(trending_date):\n",
    "    trending_datetime = datetime.strptime(str(trending_date), \"%Y-%m-%d\")\n",
    "    start_date = trending_datetime + relativedelta(weekday=MO(-1))\n",
    "    end_date = trending_datetime + relativedelta(weekday=SU(1))\n",
    "    return start_date, end_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc6f15d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:43:58.242497Z",
     "start_time": "2024-08-23T23:43:58.084266Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split video ids on 7-days chunks\n",
    "df = videos_df.select(\n",
    "        col(\"video_id\"),\n",
    "        F.to_date(F.from_unixtime(F.unix_timestamp(col(\"trending_date\"), \"yy.dd.MM\"))).alias(\"trending_date\"), \n",
    "        col(\"views\").cast(t.LongType()).alias(\"views\"), \n",
    "        col(\"category_id\")\n",
    "    )\n",
    "\n",
    "chunks_df = df.withColumn(\"week_dates\", get_week_dates_udf(col(\"trending_date\"))) \\\n",
    "                .select(\n",
    "                    col(\"video_id\"),\n",
    "                    col(\"views\"),\n",
    "                    col(\"category_id\"),\n",
    "                    col(\"trending_date\"),\n",
    "                    col(\"week_dates.start_date\").alias(\"start_date\"),\n",
    "                    col(\"week_dates.end_date\").alias(\"end_date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d7250ab",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-23T23:39:49.386041Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/30 02:39:12 ERROR Executor: Exception in task 0.0 in stage 66.0 (TID 46)\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/Users/denys_herasymuk/Programs/spark-3.5.0-bin-hadoop3/python/lib/pyspark.zip/pyspark/worker.py\", line 1104, in main\n",
      "    \"driver_version\": str(version),\n",
      "pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 7) than that in driver 3.12, PySpark cannot run with different minor versions.\n",
      "Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.sql.execution.python.BasePythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:94)\n",
      "\tat org.apache.spark.sql.execution.python.BasePythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:75)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "24/08/30 02:39:12 WARN TaskSetManager: Lost task 0.0 in stage 66.0 (TID 46) (192.168.0.196 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/Users/denys_herasymuk/Programs/spark-3.5.0-bin-hadoop3/python/lib/pyspark.zip/pyspark/worker.py\", line 1104, in main\n",
      "    \"driver_version\": str(version),\n",
      "pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 7) than that in driver 3.12, PySpark cannot run with different minor versions.\n",
      "Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.sql.execution.python.BasePythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:94)\n",
      "\tat org.apache.spark.sql.execution.python.BasePythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:75)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "\n",
      "24/08/30 02:39:12 ERROR TaskSetManager: Task 0 in stage 66.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "ename": "PythonException",
     "evalue": "\n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/Users/denys_herasymuk/Programs/spark-3.5.0-bin-hadoop3/python/lib/pyspark.zip/pyspark/worker.py\", line 1104, in main\n    \"driver_version\": str(version),\npyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 7) than that in driver 3.12, PySpark cannot run with different minor versions.\nPlease check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mchunks_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programs/spark-3.5.0-bin-hadoop3/python/pyspark/sql/dataframe.py:959\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m    954\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    955\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m    956\u001b[0m     )\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Programs/spark-3.5.0-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Programs/spark-3.5.0-bin-hadoop3/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/Users/denys_herasymuk/Programs/spark-3.5.0-bin-hadoop3/python/lib/pyspark.zip/pyspark/worker.py\", line 1104, in main\n    \"driver_version\": str(version),\npyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 7) than that in driver 3.12, PySpark cannot run with different minor versions.\nPlease check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.\n"
     ]
    }
   ],
   "source": [
    "chunks_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d61e0fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:40:18.305654Z",
     "start_time": "2024-08-23T23:40:18.292794Z"
    }
   },
   "outputs": [],
   "source": [
    "# Count number of video appearance during this 7 days. \n",
    "# And filter video ids, which appeared more than once in its period chunk\n",
    "weekly_video_views_df = (\n",
    "    chunks_df\n",
    "        .groupBy(\"video_id\", \"category_id\", \"start_date\", \"end_date\")\n",
    "        .agg(\n",
    "            F.count(\"video_id\").alias(\"video_count\"), \n",
    "            F.collect_list(col(\"views\")).alias(\"views_lst\")\n",
    "        )\n",
    "        .where(col(\"video_count\") >= 2)\n",
    "        .select(\n",
    "            col(\"video_id\"),\n",
    "            col(\"start_date\"),\n",
    "            col(\"end_date\"),\n",
    "            col(\"category_id\"),\n",
    "            col(\"views_lst\")\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e95578c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:40:20.572867Z",
     "start_time": "2024-08-23T23:40:20.551613Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/30 02:39:35 ERROR Executor: Exception in task 0.0 in stage 67.0 (TID 47)\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/Users/denys_herasymuk/Programs/spark-3.5.0-bin-hadoop3/python/lib/pyspark.zip/pyspark/worker.py\", line 1104, in main\n",
      "    \"driver_version\": str(version),\n",
      "pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 7) than that in driver 3.12, PySpark cannot run with different minor versions.\n",
      "Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.sql.execution.python.BasePythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:94)\n",
      "\tat org.apache.spark.sql.execution.python.BasePythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:75)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec.$anonfun$doExecute$1(ObjectHashAggregateExec.scala:92)\n",
      "\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec.$anonfun$doExecute$1$adapted(ObjectHashAggregateExec.scala:90)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2(RDD.scala:877)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2$adapted(RDD.scala:877)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "24/08/30 02:39:35 WARN TaskSetManager: Lost task 0.0 in stage 67.0 (TID 47) (192.168.0.196 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/Users/denys_herasymuk/Programs/spark-3.5.0-bin-hadoop3/python/lib/pyspark.zip/pyspark/worker.py\", line 1104, in main\n",
      "    \"driver_version\": str(version),\n",
      "pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 7) than that in driver 3.12, PySpark cannot run with different minor versions.\n",
      "Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.sql.execution.python.BasePythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:94)\n",
      "\tat org.apache.spark.sql.execution.python.BasePythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:75)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec.$anonfun$doExecute$1(ObjectHashAggregateExec.scala:92)\n",
      "\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec.$anonfun$doExecute$1$adapted(ObjectHashAggregateExec.scala:90)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2(RDD.scala:877)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2$adapted(RDD.scala:877)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "\n",
      "24/08/30 02:39:35 ERROR TaskSetManager: Task 0 in stage 67.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "ename": "PythonException",
     "evalue": "\n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/Users/denys_herasymuk/Programs/spark-3.5.0-bin-hadoop3/python/lib/pyspark.zip/pyspark/worker.py\", line 1104, in main\n    \"driver_version\": str(version),\npyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 7) than that in driver 3.12, PySpark cannot run with different minor versions.\nPlease check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 16\u001b[0m\n\u001b[1;32m      3\u001b[0m window \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m.\u001b[39mpartitionBy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_date\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_date\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39morderBy(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_views\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdesc())\n\u001b[1;32m      4\u001b[0m weekly_most_popular_categories_df \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      5\u001b[0m     weekly_video_views_df\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mviews_delta\u001b[39m\u001b[38;5;124m\"\u001b[39m, F\u001b[38;5;241m.\u001b[39marray_max(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mviews_lst\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m-\u001b[39m F\u001b[38;5;241m.\u001b[39marray_min(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mviews_lst\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;241m.\u001b[39mwhere(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m \u001b[43mweekly_most_popular_categories_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoPandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m~/Programs/spark-3.5.0-bin-hadoop3/python/pyspark/sql/pandas/conversion.py:202\u001b[0m, in \u001b[0;36mPandasConversionMixin.toPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m# Below is toPandas without Arrow optimization.\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(rows) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    204\u001b[0m     pdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(\n\u001b[1;32m    205\u001b[0m         rows, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(rows)), columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     )\n",
      "File \u001b[0;32m~/Programs/spark-3.5.0-bin-hadoop3/python/pyspark/sql/dataframe.py:1257\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[1;32m   1238\u001b[0m \n\u001b[1;32m   1239\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;124;03m[Row(age=14, name='Tom'), Row(age=23, name='Alice'), Row(age=16, name='Bob')]\u001b[39;00m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc):\n\u001b[0;32m-> 1257\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectToPython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[0;32m~/Programs/spark-3.5.0-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Programs/spark-3.5.0-bin-hadoop3/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/Users/denys_herasymuk/Programs/spark-3.5.0-bin-hadoop3/python/lib/pyspark.zip/pyspark/worker.py\", line 1104, in main\n    \"driver_version\": str(version),\npyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 7) than that in driver 3.12, PySpark cannot run with different minor versions.\nPlease check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.\n"
     ]
    }
   ],
   "source": [
    "# Get views_delta for videos, which relates to the same period chunk and category, sum it \n",
    "# and find the mpst popular category for each week\n",
    "window = w.partitionBy(\"start_date\", \"end_date\").orderBy(col(\"total_views\").desc())\n",
    "weekly_most_popular_categories_df = (\n",
    "    weekly_video_views_df\n",
    "        .withColumn(\"views_delta\", F.array_max(col(\"views_lst\")) - F.array_min(col(\"views_lst\")))\n",
    "        .groupBy(\"start_date\", \"end_date\", \"category_id\")\n",
    "        .agg(\n",
    "            F.count(\"video_id\").alias(\"number_of_videos\"), \n",
    "            F.sum(col(\"views_delta\")).alias(\"total_views\"),\n",
    "            F.collect_list(col(\"video_id\")).alias(\"video_ids_lst\")\n",
    "        )\n",
    "        .withColumn(\"rank\", F.row_number().over(window))\n",
    "        .where(col(\"rank\") == 1)\n",
    ")\n",
    "weekly_most_popular_categories_df.toPandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ceb0c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:39:49.390945Z",
     "start_time": "2024-08-23T23:39:49.390757Z"
    }
   },
   "outputs": [],
   "source": [
    "# Join to get category titles\n",
    "final_df = (\n",
    "    weekly_most_popular_categories_df.alias(\"df1\")\n",
    "        .join(video_categories_df.alias(\"df2\"), col(\"df1.category_id\") == col(\"df2.id\"), how=\"left\")\n",
    "        .sort(col(\"df1.start_date\").desc())\n",
    "        .select(\n",
    "            col(\"df1.start_date\"),\n",
    "            col(\"df1.end_date\"),\n",
    "            col(\"df1.category_id\"),\n",
    "            col(\"df2.title\").alias(\"category_name\"),\n",
    "            col(\"df1.number_of_videos\"),\n",
    "            col(\"df1.total_views\"),\n",
    "            col(\"df1.video_ids_lst\").alias(\"video_ids\")\n",
    "        )\n",
    ")\n",
    "final_df.toPandas().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad1521f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-23T23:39:49.392353Z"
    }
   },
   "outputs": [],
   "source": [
    "final_df = final_df.select(\n",
    "                            F.struct(\n",
    "                                col(\"start_date\"),\n",
    "                                col(\"end_date\"),\n",
    "                                col(\"category_id\"),\n",
    "                                col(\"category_name\"),\n",
    "                                col(\"number_of_videos\"),\n",
    "                                col(\"total_views\"),\n",
    "                                col(\"video_ids\")\n",
    "                            ).alias(\"week\")\n",
    "                        )\n",
    "final_df.toPandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4ea4de",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-23T23:39:49.393777Z"
    }
   },
   "outputs": [],
   "source": [
    "q2_weeks_df = convert_df_to_column_array(final_df, from_col=\"week\", to_col=\"weeks\")\n",
    "df_print(q2_weeks_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b6199b",
   "metadata": {},
   "source": [
    "## Query 3\n",
    "\n",
    "**Description:** What were the 10 most used tags amongst trending videos for each 30days time period?\n",
    "Note, if during the specified period the same video appears multiple times,\n",
    "you should count tags related to that video only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8936dceb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:40:25.679227Z",
     "start_time": "2024-08-23T23:40:24.380115Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Casting to unit-less dtype 'datetime64' is not supported. Pass e.g. 'datetime64[ns]' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 15\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create 30-days windows and filter periods by distinct video_ids\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      3\u001b[0m     videos_df\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m'\u001b[39m, F\u001b[38;5;241m.\u001b[39mregexp_replace(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m         )\u001b[38;5;241m.\u001b[39mdistinct()\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 15\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoPandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m~/UCU/Teacher_Assistant/System_Design_Course/course_venv/lib/python3.9/site-packages/pyspark/sql/pandas/conversion.py:248\u001b[0m, in \u001b[0;36mPandasConversionMixin.toPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    245\u001b[0m should_check_timedelta \u001b[38;5;241m=\u001b[39m is_timedelta64_dtype(t) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pdf) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_timedelta64_dtype(t)) \u001b[38;5;129;01mor\u001b[39;00m should_check_timedelta:\n\u001b[0;32m--> 248\u001b[0m     series \u001b[38;5;241m=\u001b[39m \u001b[43mseries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m catch_warnings():\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PerformanceWarning\n",
      "File \u001b[0;32m~/UCU/Teacher_Assistant/System_Design_Course/course_venv/lib/python3.9/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/UCU/Teacher_Assistant/System_Design_Course/course_venv/lib/python3.9/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/UCU/Teacher_Assistant/System_Design_Course/course_venv/lib/python3.9/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/UCU/Teacher_Assistant/System_Design_Course/course_venv/lib/python3.9/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/UCU/Teacher_Assistant/System_Design_Course/course_venv/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/UCU/Teacher_Assistant/System_Design_Course/course_venv/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:179\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/UCU/Teacher_Assistant/System_Design_Course/course_venv/lib/python3.9/site-packages/pandas/core/arrays/datetimes.py:732\u001b[0m, in \u001b[0;36mDatetimeArray.astype\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    721\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use .astype to convert from timezone-aware dtype to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimezone-naive dtype. Use obj.tz_localize(None) or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    723\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobj.tz_convert(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUTC\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m).tz_localize(None) instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    724\u001b[0m     )\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    727\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_np_dtype(dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_unitless(dtype)\n\u001b[1;32m    731\u001b[0m ):\n\u001b[0;32m--> 732\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    733\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCasting to unit-less dtype \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime64\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not supported. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    734\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass e.g. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime64[ns]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    735\u001b[0m     )\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, PeriodDtype):\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_period(freq\u001b[38;5;241m=\u001b[39mdtype\u001b[38;5;241m.\u001b[39mfreq)\n",
      "\u001b[0;31mTypeError\u001b[0m: Casting to unit-less dtype 'datetime64' is not supported. Pass e.g. 'datetime64[ns]' instead."
     ]
    }
   ],
   "source": [
    "# Create 30-days windows and filter periods by distinct video_ids\n",
    "df = (\n",
    "    videos_df\n",
    "        .withColumn('tags', F.regexp_replace(col(\"tags\"), '\\\"', ''))\n",
    "        .withColumn('trending_date',\n",
    "                    F.to_date(F.from_unixtime(F.unix_timestamp(col(\"trending_date\"), \"yy.dd.MM\"))) )\n",
    "        .withColumn(\"30_days_period\", F.window(\"trending_date\", \"30 days\"))\n",
    "        .select(\n",
    "            col('video_id'),\n",
    "            col('tags'),\n",
    "            col('30_days_period.start').alias('start_date'),\n",
    "            col('30_days_period.end').alias('end_date')\n",
    "        ).distinct()\n",
    ")\n",
    "df.toPandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507fb5dd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-23T23:39:49.397085Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if window function worked correctly\n",
    "df.select(['start_date', 'end_date']).distinct().sort(col('start_date')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5d2b53",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-23T23:39:49.398539Z"
    }
   },
   "outputs": [],
   "source": [
    "# Group by 30-days periods and count number of tags and video_ids for each period \n",
    "period_df = (\n",
    "      df\n",
    "        .withColumn('tags_array', F.split(col('tags'), \"\\|\"))\n",
    "        .withColumn('tag', F.explode(col('tags_array')))\n",
    "        .groupBy('tag', 'start_date', 'end_date')\n",
    "        .agg(\n",
    "            F.count(col('video_id')).alias('number_of_videos'), \n",
    "            F.collect_list(col('video_id')).alias('video_ids')\n",
    "        )\n",
    "        .select(['tag', 'number_of_videos', 'video_ids', 'start_date', 'end_date'])\n",
    ")\n",
    "df_print(period_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db76fc4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:39:49.403041Z",
     "start_time": "2024-08-23T23:39:49.399904Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sort number_of_videos in descending order. Take top 10 most used tags\n",
    "window =  w.partitionBy(\"start_date\", \"end_date\").orderBy(col(\"number_of_videos\").desc())\n",
    "top_tags_df = (\n",
    "    period_df\n",
    "            .withColumn(\"rank\", F.row_number().over(window))\n",
    "            .where(col(\"rank\") <= 10)\n",
    "            .select(\n",
    "                col(\"start_date\"),\n",
    "                col(\"end_date\"),\n",
    "                F.struct(\n",
    "                    col(\"tag\"),\n",
    "                    col(\"number_of_videos\"),\n",
    "                    col(\"video_ids\")\n",
    "                ).alias(\"tag_stat\")\n",
    "            )\n",
    "    )\n",
    "df_print(top_tags_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742b7b8d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-23T23:39:49.401546Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transform to month's schema\n",
    "month_df = (\n",
    "    top_tags_df\n",
    "        .groupBy(\"start_date\", \"end_date\")\n",
    "        .agg(F.collect_list(col(\"tag_stat\")).alias(\"tags\"))\n",
    "        .select(F.struct(\n",
    "            col(\"start_date\"),\n",
    "            col(\"end_date\"),\n",
    "            col(\"tags\")\n",
    "        ).alias(\"month\"))\n",
    ")\n",
    "df_print(month_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d885848f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:39:49.404324Z",
     "start_time": "2024-08-23T23:39:49.403136Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transform to months' schema\n",
    "months_df = convert_df_to_column_array(month_df, from_col=\"month\", to_col=\"months\")\n",
    "df_print(months_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2197cb37",
   "metadata": {},
   "source": [
    "## Query 4\n",
    "\n",
    "**Description:** Show the top 20 channels by the number of views for the whole period.\n",
    "Note, if there are multiple appearances of the same video for some channel,\n",
    "you should take into account only the last appearance (with the highest\n",
    "number of views)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dda763",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-23T23:39:49.404114Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create initial dataframe for the query\n",
    "df = videos_df\\\n",
    "        .withColumn(\"trending_date\", F.to_date(F.from_unixtime(F.unix_timestamp(col(\"trending_date\"), \"yy.dd.MM\"))))\\\n",
    "        .select(\n",
    "            col(\"channel_title\"),\n",
    "            col(\"video_id\"),\n",
    "            col(\"trending_date\"),\n",
    "            col(\"views\").cast(t.LongType()).alias(\"views\")\n",
    "        )\n",
    "\n",
    "\n",
    "# Group by channel_title and video_id. Take video with max number of views for the same channel\n",
    "window = w.partitionBy(\"channel_title\", \"video_id\").orderBy(col(\"views\").desc())\n",
    "filtered_videos_df = (\n",
    "      df\n",
    "        .withColumn(\"rank\", F.row_number().over(window))\n",
    "        .where(col(\"rank\") == 1)\n",
    ")\n",
    "df_print(filtered_videos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0296cf45",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-23T23:39:49.405010Z"
    }
   },
   "outputs": [],
   "source": [
    "# Group by channel_title to get a number of views for all popular videos.\n",
    "# Also get top 20 channels by the number of views for the whole period\n",
    "most_popular_channels = (\n",
    "    filtered_videos_df\n",
    "        .withColumn(\"video_stat\", \n",
    "                    F.struct(\n",
    "                       col(\"video_id\"),\n",
    "                       col(\"views\")\n",
    "                   ))\n",
    "        .groupBy(\"channel_title\")\n",
    "        .agg(\n",
    "            F.sum(col(\"views\")).alias(\"total_views\"),\n",
    "            F.min(\"trending_date\").alias(\"start_date\"),\n",
    "            F.max(\"trending_date\").alias(\"end_date\"),\n",
    "            F.collect_list(col(\"video_stat\")).alias(\"videos_views\")\n",
    "        )\n",
    "        .orderBy(col(\"total_views\").desc())\n",
    "        .select(\n",
    "            F.struct(\n",
    "                col(\"channel_title\").alias(\"channel_name\"),\n",
    "                col(\"start_date\"),\n",
    "                col(\"end_date\"),\n",
    "                col(\"total_views\"),\n",
    "                col(\"videos_views\")\n",
    "            ).alias(\"channel\")\n",
    "        )\n",
    "        .limit(20)\n",
    ")\n",
    "df_print(most_popular_channels, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfaa6ef",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-23T23:39:49.405859Z"
    }
   },
   "outputs": [],
   "source": [
    "q4_channels_df = convert_df_to_column_array(most_popular_channels, from_col=\"channel\", to_col=\"channels\")\n",
    "df_print(q4_channels_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c965d0",
   "metadata": {},
   "source": [
    "## Query 5\n",
    "\n",
    "**Description:** Show the top 10 channels with videos trending for the highest number of days\n",
    "(it doesn't need to be a consecutive period of time) for the whole period.\n",
    "In order to calculate it, you may use the results from the question No1.\n",
    "The total_trending_days count will be a sum of the numbers of trending days\n",
    "for videos from this channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90463fdb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-23T23:39:49.406760Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use detailed_most_trending_df, which was created for query 1\n",
    "df_print(detailed_most_trending_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab689d0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-23T23:39:49.407585Z"
    }
   },
   "outputs": [],
   "source": [
    "video_id_to_channel_df = videos_df.select(['video_id', 'channel_title']).distinct()\n",
    "\n",
    "# Get channel names for each video_id\n",
    "full_detailed_most_trending_df = (\n",
    "    detailed_most_trending_df.alias('df1')\n",
    "        .join(video_id_to_channel_df.alias('df2'),\n",
    "                col(\"df1.video_id\") == col(\"df2.video_id\"), how='inner')\n",
    "        .select(\n",
    "            col(\"channel_title\").alias(\"channel_name\"),\n",
    "            F.struct(\n",
    "                col(\"df1.video_id\").alias(\"video_id\"),\n",
    "                col(\"df1.title\").alias(\"video_title\"),\n",
    "                col(\"df1.num_trending_days\").alias(\"trending_days\")\n",
    "            ).alias(\"video_day\")\n",
    "        )\n",
    ")\n",
    "\n",
    "\n",
    "# Find top 10 channels with videos trending for the highest number of days\n",
    "top_channels_df = (\n",
    "    full_detailed_most_trending_df\n",
    "        .groupBy(\"channel_name\")\n",
    "        .agg(\n",
    "            F.collect_list(col(\"video_day\")).alias(\"videos_days\"),\n",
    "            F.sum(col(\"video_day.trending_days\")).alias(\"total_trending_days\")\n",
    "        )\n",
    "        .orderBy(col(\"total_trending_days\").desc())\n",
    "        .select(\n",
    "            F.struct(\n",
    "                col(\"channel_name\"),\n",
    "                col(\"total_trending_days\"),\n",
    "                col(\"videos_days\")\n",
    "            ).alias(\"channel\")\n",
    "        ).limit(10)\n",
    ")\n",
    "df_print(top_channels_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4606be7d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-23T23:39:49.408586Z"
    }
   },
   "outputs": [],
   "source": [
    "q5_channels_df = convert_df_to_column_array(top_channels_df, from_col=\"channel\", to_col=\"channels\")\n",
    "df_print(q5_channels_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92f7ccb",
   "metadata": {},
   "source": [
    "## Query 6\n",
    "\n",
    "**Description:** Show the top 10 videos by the ratio of likes/dislikes for each category\n",
    "for the whole period. You should consider only videos with more than 100K views.\n",
    "If the same video occurs multiple times you should take the record when\n",
    "the ratio was the highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78df7d96",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-23T23:39:49.409676Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create initial dataframe for the query. Filter videos, which have more than 100K views\n",
    "df = (\n",
    "    videos_df\n",
    "        .where(col(\"views\") > 100_000)\n",
    "        .select(\n",
    "            col('video_id'),\n",
    "            col(\"category_id\"),\n",
    "            col(\"title\").alias(\"video_title\"),\n",
    "            col(\"views\").cast(t.LongType()).alias(\"views\"),\n",
    "            col(\"likes\").cast(t.LongType()).alias(\"likes\"), \n",
    "            col(\"dislikes\").cast(t.LongType()).alias(\"dislikes\")\n",
    "        )\n",
    ")\n",
    "\n",
    "\n",
    "# Count the ratio of likes/dislikes for each video. \n",
    "# If the same video occurs multiple times you should take the record when the ratio was the highest\n",
    "video_ratio_window = w.partitionBy(\"video_id\").orderBy(col(\"ratio_likes_dislikes\").desc())\n",
    "video_ratios_df = (\n",
    "       df\n",
    "        .withColumn(\"ratio_likes_dislikes\", col(\"likes\") / col(\"dislikes\"))\n",
    "        .withColumn(\"video_ratio_rank\", F.row_number().over(video_ratio_window))\n",
    "        .where(col(\"video_ratio_rank\") == 1)\n",
    ")\n",
    "\n",
    "\n",
    "# Group by category and get top 10 videos by the ratio of likes/dislikes for each category\n",
    "category_ratio_window =  w.partitionBy(\"category_id\").orderBy(col(\"ratio_likes_dislikes\").desc())\n",
    "category_ratios_df = (\n",
    "    video_ratios_df.alias(\"df1\")\n",
    "        .withColumn(\"category_ratio_rank\", F.row_number().over(category_ratio_window))\n",
    "        .where(col(\"category_ratio_rank\") <= 10)\n",
    "        .join(video_categories_df.alias(\"df2\"),\n",
    "             col(\"df1.category_id\") == col(\"df2.id\"))\n",
    "        .select(\n",
    "            col(\"category_id\"),\n",
    "            col(\"df2.title\").alias(\"category_name\"),\n",
    "            F.struct(\n",
    "                col(\"video_id\"),\n",
    "                col(\"video_title\"),\n",
    "                col(\"ratio_likes_dislikes\"),\n",
    "                col(\"views\")\n",
    "            ).alias(\"video\")\n",
    "        )\n",
    ")\n",
    "df_print(category_ratios_df, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d15206",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-23T23:39:49.410718Z"
    }
   },
   "outputs": [],
   "source": [
    "top_category_videos_df = (\n",
    "    category_ratios_df\n",
    "        .groupBy(\"category_id\", \"category_name\")\n",
    "        .agg(\n",
    "            F.collect_list(col(\"video\")).alias(\"videos\")\n",
    "        )\n",
    "        .select(\n",
    "            F.struct(\n",
    "                col(\"category_id\"),\n",
    "                col(\"category_name\"),\n",
    "                col(\"videos\")\n",
    "            ).alias(\"category\")\n",
    "        )\n",
    ")\n",
    "df_print(top_category_videos_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e9720b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-23T23:39:49.411826Z"
    }
   },
   "outputs": [],
   "source": [
    "q6_category_videos_df = convert_df_to_column_array(top_category_videos_df, from_col=\"category\", to_col=\"categories\")\n",
    "df_print(q6_category_videos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374b3032",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-23T23:39:49.412786Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
